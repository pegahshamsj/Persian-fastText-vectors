# Persian-fastText-vectors
 Trained on 70G data
 <br/>
Here we trained fastText on a huge Persian dataset. The dataset is available [here](https://github.com/persiannlp/persian-raw-text).
<br/>
Generated vectors contain about 6742635 words. Each word is a vector of dimensions 300.
<br/>
We used cbow model for computing word representations.
<br/>
1-5 grams of words used for training.
<br/>
You can also reduce the dimension if you needed.
<br/>
More instructions is provided [here](https://fasttext.cc/docs/en/support.html).
