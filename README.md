# Persian-fastText-vectors
 Trained on 70G data
 <br/>
Here we trained fastText on a huge Persian dataset. The dataset is available [here](https://github.com/persiannlp/persian-raw-text).
Generated vectors contain about 6742635 words. Each word is a vector of dimensions 300.
We used cbow model for computing word representations.
1-5 grams of words used for training.
You can also reduce the dimension if you needed.
More instructions is provided [here](https://fasttext.cc/docs/en/support.html)
